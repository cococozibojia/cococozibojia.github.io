<!doctype html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- bulma css template -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <!-- ionicons -->
  <script type="module" src="https://unpkg.com/ionicons@7.1.0/dist/ionicons/ionicons.esm.js"></script>
  <script nomodule src="https://unpkg.com/ionicons@7.1.0/dist/ionicons/ionicons.js"></script>
  <!-- model viewer -->
  <script type="module" src="https://ajax.googleapis.com/ajax/libs/model-viewer/3.1.1/model-viewer.min.js"></script>
  <title>
    CoCoCo
  </title>
  <link rel="icon" href="icon.ico">
</head>
<body>
  <section class="section">

  <div class="container has-text-centered">
    <!-- paper title -->
    <p class="title is-3"> CoCoCo: Improving Text-Guided Video Inpainting for Better Consistency, Controllability and Compatibility </p>
    <!-- authors -->
    <p class="title is-5 mt-2"> 
      <a href="https://zibojia.github.io/" target="_blank">Bojia Zi</a><sup>1</sup>, 
      <a href="https://shihaozhaozsh.github.io/" target="_blank">Shihao Zhao</a><sup>2</sup>, 
      <a href="https://scholar.google.com/citations?user=odjSydQAAAAJ&hl=zh-CN" target="_blank">Xianbiao Qi</a><sup>4</sup>, 
      <a href="https://scholar.google.com/citations?user=mt5mvZ8AAAAJ&hl=en" target="_blank">Jianan Wang</a><sup>4</sup>,
      <a href="https://openreview.net/profile?id=~Yukai_Shi3" target="_blank">Yukai Shi</a><sup>3</sup>,
      <a href="https://github.com/qyc-98" target="_blank">Qianyu Chen</a><sup>1</sup>,
      <a href="https://scholar.google.com/citations?hl=zh-CN&authuser=1&user=djpQeLEAAAAJ" target="_blank">Bin Liang</a><sup>1</sup>,
      <a href="https://scholar.google.com/citations?hl=en&user=fyMni2cAAAAJ" target="_blank">Kam-Fai Wong</a><sup>1</sup>,
      <a href="https://scholar.google.com/citations?hl=en&user=fIlGZToAAAAJ" target="_blank">Lei Zhang</a><sup>4</sup>
    </p>
    <!-- affiliations -->
    <p class="subtitle is-5"> 
      <sup>1</sup> The Chinese University of Hong Kong &nbsp;
      <sup>2</sup> The University of Hong Kong &nbsp;
      <sup>3</sup> Tsinghua University &nbsp;
      <sup>4</sup> International Digital Economy Academy
    </p>

    <!-- other links -->
    <div class="is-flex is-justify-content-center">
      <span class="icon-text mx-1">
        <a class="button is-dark" href="https://arxiv.org/abs/2403.12035" role="button" target="_blank"> <span class="icon"> <ion-icon name="document-outline"></ion-icon> </span> <span> Arxiv </span>  </a> 
      </span>
      <span class="icon-text mx-1">
        <a class="button is-dark" href="https://github.com" role="button" target="_blank"> <span class="icon"> <ion-icon name="logo-github"></ion-icon> </span> <span> Code </span> </a> 
      </span>
    </div>
   
  </div>

  <!-- main container -->
  <div class="container is-max-desktop has-text-centered">

    <!-- abstract -->
    <p class="title is-3 mt-5 has-text-centered"> Abstract </p>
    <p class="content is-size-6 has-text-left">
Recent advancements in video generation have been remarkable, yet many existing methods struggle with issues of consistency and poor text-video alignment. Moreover, the field lacks effective techniques for text-guided video inpainting, a stark contrast to the well-explored domain of text-guided image inpainting. To this end, this paper proposes a novel text-guided video inpainting model that achieves better consistency, controllability and compatibility. Specifically, we introduce a simple but efficient motion capture module to preserve motion consistency, and design an instance-aware region selection instead of a random region selection to obtain better textual controllability, and utilize a novel strategy to inject some personalized models into our CoCoCo model and thus obtain better model compatibility. Extensive experiments show that our model can generate high-quality video clips. Meanwhile, our model shows better motion consistency, textual controllability and model compatibility.    </p>
   <th class="has-text-centered"> <video muted controls autoplay loop> <source src="videos/output3.mp4" type="video/mp4"> </video> </th>
    <th class="has-text-centered"> demo video </th>
    
    <p class="title is-size-4 mt-5 has-text-centered"> Motion Capture Module </p>
    <p class="content has-text-centered is-size-6">
      We propose a novel motion capture module. It consists of three types attention block, including two previously used temporal attention layers, a newly introduced damped global attention layer and a textual cross attention layer. The new motion capture module can enable the model to have better motion consistency and text-video controllability.
    </p>
    <img src="./images/image1.png" alt="Description of the image" width="500">
    <img src="./images/image2.png" alt="Description of the image" width="500">


    <p class="title is-size-4 mt-5 has-text-centered"> Instance-Aware Region Selection </p>
    <p class="content has-text-centered is-size-6">
      We design a new instance-aware region selection strategy instead of a random mask selection strategy used in previous method. The new strategy can help the model achieve better text-video controllability.
    </p>
    <img src="./images/image3.png" alt="Description of the image" width="500">
    
    <p class="title is-size-4 mt-5 has-text-centered">T2I Model for Video Inpainting</p>
    <p class="content has-text-centered is-size-6">
     We introduce a novel strategy to transform some personalized generation models, and then plug them into our our text-guided video inpainting model. This strategy can enhance the compatibility of our model.
    </p>
    <img src="./images/image4.png" alt="Description of the image" width="500">

    <!-- citation -->
    <div class="card mt-4">
      <header class="card-header">
        <p class="card-header-title"> Citation </p>
      </header>
      <div class="card-content is-size-5 has-text-left">
<pre><code>@article{zi2024cococo,
  title={CoCoCo: Improving Text-Guided Video Inpainting for Better blue Consistency, Controllability and Compatibility},
  author={Zi, Bojia and Zhao, Shihao and Qi, Xianbiao and Wang, Jianan and Shi, Yukai and Chen, Qianyu and Liang, Bin and Wong, Kam-Fai and Zhang, Lei},
  journal={arXiv preprint arXiv:2403.12305},
  year={2023}
}</code></pre>
      </div>
    </div>
  </div>


  </section>
</body>
</html>
