<!doctype html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- bulma css template -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <!-- ionicons -->
  <script type="module" src="https://unpkg.com/ionicons@7.1.0/dist/ionicons/ionicons.esm.js"></script>
  <script nomodule src="https://unpkg.com/ionicons@7.1.0/dist/ionicons/ionicons.js"></script>
  <!-- model viewer -->
  <script type="module" src="https://ajax.googleapis.com/ajax/libs/model-viewer/3.1.1/model-viewer.min.js"></script>
  <title>
    DreamGaussian
  </title>
  <link rel="icon" href="icon.ico">
</head>
<body>
  <section class="section">

  <div class="container has-text-centered">
    <!-- paper title -->
    <p class="title is-3"> DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation </p>
    <!-- publication -->
    <p class="subtitle is-4"> ICLR 2024 (Oral) </p>
    <!-- authors -->
    <p class="title is-5 mt-2"> 
      <a href="https://zibojia.github.io/" target="_blank">Bojia Zi</a><sup>1</sup>, 
      <a href="https://shihaozhaozsh.github.io/" target="_blank">Shihao Zhao</a><sup>2</sup>, 
      <a href="https://scholar.google.com/citations?user=odjSydQAAAAJ&hl=zh-CN" target="_blank">Xianbiao Qi</a><sup>4</sup>, 
      <a href="https://scholar.google.com/citations?user=mt5mvZ8AAAAJ&hl=en" target="_blank">Jianan Wang</a><sup>4</sup>,
      <a href="https://openreview.net/profile?id=~Yukai_Shi3" target="_blank">Yukai Shi</a><sup>3</sup>,
      <a href="https://scholar.google.com/citations?hl=zh-CN&authuser=1&user=djpQeLEAAAAJ" target="_blank">Bin Liang</a><sup>1</sup>,
      <a href="https://scholar.google.com/citations?hl=en&user=fyMni2cAAAAJ" target="_blank">Kam-Fai Wong</a><sup>1</sup>,
      <a href="https://scholar.google.com/citations?hl=en&user=fIlGZToAAAAJ" target="_blank">Lei Zhang</a><sup>4</sup>
    </p>
    <!-- affiliations -->
    <p class="subtitle is-5"> 
      <sup>1</sup> The Chinese University of Hong Kong &nbsp;
      <sup>2</sup> The University of Hong Kong &nbsp;
      <sup>3</sup> Tsinghua University &nbsp;
      <sup>4</sup> International Digital Economy Academy
    </p>

    <!-- other links -->
    <div class="is-flex is-justify-content-center">
      <span class="icon-text mx-1">
        <a class="button is-dark" href="https://arxiv.org/abs/2309.16653" role="button" target="_blank"> <span class="icon"> <ion-icon name="document-outline"></ion-icon> </span> <span> Arxiv </span>  </a> 
      </span>
      <span class="icon-text mx-1">
        <a class="button is-dark" href="https://github.com/dreamgaussian/dreamgaussian" role="button" target="_blank"> <span class="icon"> <ion-icon name="logo-github"></ion-icon> </span> <span> Code </span> </a> 
      </span>
    </div>
   
  </div>

  <!-- main container -->
  <div class="container is-max-desktop has-text-centered">

    <!-- abstract -->
    <p class="title is-3 mt-5 has-text-centered"> Abstract </p>
    <p class="content is-size-6 has-text-left">
Recent advancements in video generation have been remarkable, yet many existing methods struggle with issues of consistency and poor text-video alignment. Moreover, the field lacks effective techniques for text-guided video inpainting, a stark contrast to the well-explored domain of text-guided image inpainting. To this end, this paper proposes a novel text-guided video inpainting model that achieves better consistency, controllability and compatibility. Specifically, we introduce a simple but efficient motion capture module to preserve motion consistency, and design an instance-aware region selection instead of a random region selection to obtain better textual controllability, and utilize a novel strategy to inject some personalized models into our CoCoCo model and thus obtain better model compatibility. Extensive experiments show that our model can generate high-quality video clips. Meanwhile, our model shows better motion consistency, textual controllability and model compatibility.    </p>
    
    <!-- results (videos) -->
    <p class="title is-3 mt-5 has-text-centered"> Convergence Speed </p>

    <p class="content has-text-centered is-size-5">
      Our method converges in 2 minutes for image-to-3D while keeping good generation quality.
    </p>
    <video muted autoplay controls loop> <source src="videos/accelerate.mp4" type="video/mp4"> </video>


    <p class="title is-3 mt-5 has-text-centered"> Image-to-3D </p>
    <video muted autoplay loop> <source src="videos/image1.mp4" type="video/mp4"> </video>
    <video muted autoplay loop> <source src="videos/image2.mp4" type="video/mp4"> </video>

    <p class="content has-text-centered is-size-5">
      We can support images with a non-zero elevation angle too!
    </p>

    <video muted autoplay loop> <source src="videos/elevation.mp4" type="video/mp4"> </video>
    
    <p class="title is-3 mt-5 has-text-centered"> Text-to-3D </p>
    <video muted autoplay loop> <source src="videos/text.mp4" type="video/mp4"> </video>

    <p class="title is-3 mt-5 has-text-centered"> Text-to-image-to-3D </p>
    <video muted autoplay loop> <source src="videos/text-to-image-to-3d.mp4" type="video/mp4"> </video>

    <p class="title is-3 mt-5 has-text-centered"> Optimization Progress </p>
    <table class="table">
      <tbody>
        <tr> 
          <th> <video muted controls autoplay loop> <source src="videos/gui.mp4" type="video/mp4"> </video> </th>
          <th> <video muted controls autoplay loop> <source src="videos/gui2.mp4" type="video/mp4"> </video> </th>
        </tr>
        <tr>
          <th class="has-text-centered"> Stage 1 (Generative Gaussian Splatting) </th>
          <th class="has-text-centered"> Stage 2 (Mesh Texture Refinement) </th>
        </tr>
    </table>
    <p class="content has-text-centered is-size-5">
      Videos are played at the original speed and recorded on an NVIDIA 3070 (8GB).
    </p>

    <!-- 3d model viewer -->
    <p class="title is-3 mt-5 has-text-centered"> Exported Meshes </p>
    <div class="level">
      <div class="level-item">
        <model-viewer src="meshes/anya.glb" poster="meshes/anya.jpg" style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" camera-controls touch-action="pan-y"></model-viewer>
      </div>
      <div class="level-item">
        <model-viewer src="meshes/luigi.glb" poster="meshes/luigi.jpg" style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" camera-controls touch-action="pan-y"></model-viewer>
      </div>
      <div class="level-item">
        <model-viewer src="meshes/zelda.glb" poster="meshes/zelda.jpg" style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" camera-controls touch-action="pan-y"></model-viewer>
      </div>
      <div class="level-item">
        <model-viewer src="meshes/toy.glb" poster="meshes/toy.jpg" style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" camera-controls touch-action="pan-y"></model-viewer>
      </div>
    </div>
    
    <p class="title is-3 mt-5 has-text-centered"> Mesh Animations </p>
    <p class="content has-text-centered is-size-5">
      The following results are animated by <a href="https://www.mixamo.com/">Mixamo</a>.
    </p>
    <div class="level">
      <div class="level-item">
        <model-viewer src="meshes/rabbit_animate.glb" poster="meshes/toy2.jpg" style="width: 100%; height: 300px;" autoplay shadow-intensity="1" camera-controls touch-action="pan-y"></model-viewer>
      </div>
      <div class="level-item">
        <model-viewer src="meshes/girl_animate.glb" poster="meshes/girl_animate.png" style="width: 100%; height: 300px;" autoplay shadow-intensity="1" camera-controls touch-action="pan-y"></model-viewer>
      </div>
      <div class="level-item">
        <model-viewer src="meshes/boy_animate.glb" poster="meshes/boy_animate.png" style="width: 100%; height: 300px;" autoplay shadow-intensity="1" camera-controls touch-action="pan-y"></model-viewer>
      </div>
    </div>

    <!-- citation -->
    <div class="card mt-4">
      <header class="card-header">
        <p class="card-header-title"> Citation </p>
      </header>
      <div class="card-content is-size-5 has-text-left">
<pre><code>@article{tang2023dreamgaussian,
  title={DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation},
  author={Tang, Jiaxiang and Ren, Jiawei and Zhou, Hang and Liu, Ziwei and Zeng, Gang},
  journal={arXiv preprint arXiv:2309.16653},
  year={2023}
}</code></pre>
      </div>
    </div>
  </div>


  </section>
</body>
</html>
